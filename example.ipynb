{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ac3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr/sr-dublin/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install\n",
    "# pip install pandas tqdm datasets openai ollama python-dotenv\n",
    "\n",
    "# general imports\n",
    "from time import sleep\n",
    "\n",
    "# setup pandas\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# setup access to huggingface data\n",
    "from datasets import load_dataset\n",
    "\n",
    "# setup ollama\n",
    "# NOTE: Need to install ollama on system: https://ollama.com/download\n",
    "# Set up ollama server (ollama serve), and download the models you want to use (ollama pull <model>)\n",
    "# If you prefer not running ollama server, you can use transformers\n",
    "from ollama import Client as OllamaClient\n",
    "\n",
    "# setup openai\n",
    "# NOTE: Need to create .env file with OPENAI_API_KEY=xxxxxxxx\n",
    "# Get your OpenAI API key from https://platform.openai.com\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84856729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "df = load_dataset(\"refugee-law-lab/canadian-legal-data\", data_dir = \"RAD\", split = \"train\").to_pandas()\n",
    "\n",
    "# filter for language == 'en'\n",
    "df = df[df['language'] == 'en']\n",
    "\n",
    "# in df.unofficial_text remove footnotes\n",
    "df['unofficial_text'] = df['unofficial_text'].str.replace(r'\\n(?:\\d+ .+?)(?=\\n)', '', regex=True)\n",
    "\n",
    "# remove header if REASONS FOR DECISION is in the text\n",
    "print(\"Removing header\")\n",
    "def remove_header(text):\n",
    "    before, sep, after = text.partition('REASONS FOR DECISION')\n",
    "    if sep:  # found the string\n",
    "        return sep + after\n",
    "    else:\n",
    "        return text  # leave untouched if not found\n",
    "df['unofficial_text'] = df['unofficial_text'].apply(remove_header)\n",
    "\n",
    "# create sample to get outcomes for all cases\n",
    "df_sample = df.copy()\n",
    "df_sample = df_sample.sample(n=5000, random_state=888).reset_index(drop=True)\n",
    "\n",
    "# keyword search for cases realted to sexual orientation or gendier identity/expression\n",
    "keywords = [\n",
    "    'lgbt',\n",
    "    'queer',\n",
    "    'sogie',\n",
    "    'sexual orienation',\n",
    "    'gay',\n",
    "    'homosexual',\n",
    "    'lesbian',\n",
    "    'bisexual',\n",
    "    'bi-sexual',\n",
    "    'pansexual',\n",
    "    'pan-sexual',\n",
    "    'same-sex',\n",
    "    'same sex',\n",
    "    'transgender',\n",
    "    'transexual',\n",
    "    'transman',\n",
    "    'transwoman',\n",
    "    'mtf',\n",
    "    'ftm',\n",
    "    'non-binary',\n",
    "    'gender identity',\n",
    "    'gender expression',\n",
    "    'genderqueer',\n",
    "    'gender queer',\n",
    "    'gender fluid',\n",
    "    'gender-fluid',\n",
    "    'gender non-conforming',\n",
    "    'gender nonconforming',\n",
    "    'gender expansive',\n",
    "    'two spirit'\n",
    "    ]\n",
    "\n",
    "def keyword_search(text):\n",
    "    for kw in keywords:\n",
    "        if kw in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "print(\"Searching for keywords\")\n",
    "df['keyword_search'] = df['unofficial_text'].progress_apply(keyword_search)\n",
    "\n",
    "print (\"Length of en df before keyword search: \", len(df))\n",
    "df = df[df['keyword_search'] == True]\n",
    "df = df.drop(columns=['keyword_search'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print (\"Length of en df after keyword search: \", len(df))\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4657c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama: working\n",
      "OpenAI: Working\n"
     ]
    }
   ],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_ollama_completion(prompt,\n",
    "                 model = 'qwen2.5:72b',\n",
    "                 temperature = 0,\n",
    "                 num_predict = 1,\n",
    "                 host = 'http://ts-ollama:11434',  #For local use, change to 'http://localhost:11434'\n",
    "                 attempts = 3\n",
    "                 ):  \n",
    "\n",
    "    for x in range(attempts):   \n",
    "        try:\n",
    "            client = OllamaClient(host=host)\n",
    "            response = client.generate(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                options={\"temperature\": temperature, \"num_predict\": num_predict}\n",
    "            )\n",
    "            sleep(.1) # slow down requests to avoid problems with ollama server\n",
    "            return response[\"response\"]\n",
    "    \n",
    "        except:\n",
    "            print(\"Error in connection. Trying again after 10 seconds\")\n",
    "            sleep(10)\n",
    "            if x == attempts - 1:\n",
    "                print(\"Too many errors. Returning empty string.\")\n",
    "                return \"\"\n",
    "\n",
    "\n",
    "def get_openai_completion(user_message,\n",
    "        system_message=\"You are a helpful assistant to a Canadian law student\",\n",
    "        model = \"gpt-4o-mini\",\n",
    "        temperature = 0,\n",
    "        num_predict = 1):\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        max_completion_tokens = num_predict,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(\"Ollama:\", get_ollama_completion(\"If you hear me, say 'working' and nothing elese\"))\n",
    "print(\"OpenAI:\", get_openai_completion(\"If you hear me, say 'working' and nothing elese\"))\n",
    "\n",
    "\n",
    "def get_prompt(docs, question = \"Summarize the document.\\n\\n\"):\n",
    "    prompt = f\"\"\"CONTEXT: You are a legal assistant. You are provided a document and you are asked\n",
    "a question about that document. You only answer the question with no explanation\n",
    "\n",
    "DOCUMENT:\n",
    "{docs}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_question = \"\"\"True or false: In the document provided, the appeal is granted. Only answer with True or False.\"\"\"\n",
    "\n",
    "# apply to df to get ollama response (use smaller model for speed):\n",
    "df_sample['ollama_outcome'] = df_sample.progress_apply(lambda x: get_ollama_completion(get_prompt(x['unofficial_text'], outcome_question), model = 'qwen2.5:32b'), axis=1)\n",
    "\n",
    "# export to json, orient records, indent 4\n",
    "df_sample.to_json(\"RAD_sample_outcome.json\", orient=\"records\", indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33220769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences etween openai and ollama 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test for accuracy against openai gpt-4o-mini\n",
    "\n",
    "df_sample = pd.read_json(\"RAD_sample_outcome.json\", orient=\"records\")\n",
    "\n",
    "df_sample = df_sample.sample(100)\n",
    "\n",
    "outcome_question = \"\"\"True or false: In the document provided, the appeal is granted. Only answer with True or False.\"\"\"\n",
    "\n",
    "# apply to df to get openai gpt-4o-mini response:\n",
    "df_sample['openai_outcome'] = df_sample.progress_apply(lambda x: get_openai_completion(get_prompt(x['unofficial_text'], outcome_question), model = 'gpt-4o-mini'), axis=1)\n",
    "\n",
    "# len where ollama_outcome != openai_outcome\n",
    "print(\"Differences etween openai and ollama\", len(df_sample[df_sample['ollama_outcome'] != df_sample['openai_outcome']]))\n",
    "\n",
    "# export small sample to json, orient records, indent 4\n",
    "df_sample.to_json(\"RAD_small_sample_outcome_comparison.json\", orient=\"records\", indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68784fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_question = \"\"\"Multiple choice (return only the number): You are assisting a law professor in\n",
    "categorizing refugee law cases involving persecution based on sexual orientation or gender\n",
    "identity/expression. The professor is interested in the principal claimant's *allegations*, not \n",
    "whether these allegations are true or credible.\n",
    "\n",
    "Your task is to identify the category that best describes the particular social group the principal\n",
    "claimant *alleges* to belong to, based on the information in the document.\n",
    "\n",
    "Select the most appropriate category (if applicable):\n",
    "\n",
    "1. Gay man / homosexual (excluding men who also identify as bisexual or pansexual)\n",
    "2. Lesbian woman (excluding women who also identify as bisexual or pansexual)\n",
    "3. Bisexual / pansexual man (including men who identiy as *both* gay and bisexual)\n",
    "4. Bisexual / pansexual woman  (including women who identify as *both* lesbian and bisexual)\n",
    "5. Transgender / non-binary person  \n",
    "6. Other: A principal claim involving sexual orientation or gender identity/expression that does not fit categories 1-5 (including, e.g. family members or friends of LGBTQ+ individuals)\n",
    "7. Other: A principal claim that does *not* involve sexual orientation or gender identity/expression\n",
    "\n",
    "Be sure to return the number corresponding to your choice in your final answer. Do not return any other text or explanation.\"\"\"\n",
    "\n",
    "# apply to df to get ollama response (use bigger model for accuracy)\n",
    "df['ollama_type'] = df.progress_apply(lambda x: get_ollama_completion(get_prompt(x['unofficial_text'], type_question), model = 'qwen2.5:72b'), axis=1)\n",
    "\n",
    "# apply to df to get openai gpt-4o-mini response:\n",
    "df['openai_type'] = df.progress_apply(lambda x: get_openai_completion(get_prompt(x['unofficial_text'], type_question), model = 'gpt-4o-mini'), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f02c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_question = \"\"\"True or false: In the document provided, the appeal is granted. Only answer with True or False.\"\"\"\n",
    "\n",
    "# apply to df to get ollama response (use smaller model for speed):\n",
    "df['ollama_outcome'] = df.progress_apply(lambda x: get_ollama_completion(get_prompt(x['unofficial_text'], outcome_question), model = 'qwen2.5:32b'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce463ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to json\n",
    "df.to_json(\"RAD_SOGIE_type_outcome.json\", orient=\"records\", indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a51f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "df = pd.read_json(\"RAD_SOGIE_type_outcome.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of rows\n",
    "print(\"Number of rows in df:\", len(df))\n",
    "# number of rows were df.ollama == df.openai\n",
    "print(\"Types differnces qwen v openai:\", len(df[df['ollama_type'] != df['openai_type']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ab460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where there are differences between ollama and openai\n",
    "df = df[df['ollama_type'] == df['openai_type']]\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Number of rows in df after removing differences:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where type is 6 or 7 (i.e. not claim where claimant is LGBTQ+)\n",
    "df = df[(df['ollama_type'] != 6) & (df['ollama_type'] != 7)]\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Number of rows in df after removing type 6 and 7:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_types = {1:\"Gay man\", 2: \"Lesbian\", 3: \"Bisexual man\", 4: \"Bisexual woman\", 5: \"Transgeder\"}\n",
    "\n",
    "# iterate through dict\n",
    "for ollama_type in ollama_types:\n",
    "    num_claims = len(df[df['ollama_type'] == ollama_type])\n",
    "    percent_claims = len(df[df['ollama_type'] == ollama_type])/len(df)*100\n",
    "    success_rate = len(df[(df['ollama_type'] == ollama_type) & (df['ollama_outcome'] == \"True\")])/num_claims*100\n",
    "    print(f\"{ollama_types[ollama_type]} claims: {num_claims} ({percent_claims:.1f}%), with success rate of {success_rate:.1f}%\")\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
